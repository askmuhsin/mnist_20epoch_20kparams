{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import lightning as L\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from models.cnn import AdvancedMNISTCNN\n",
    "from data.mnist import MNISTDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: {'learning_rate': 0.003, 'dropout': 0.05, 'batch_size': 32, 'max_epochs': 20, 'num_workers': 4, 'data_dir': '../data', 'weight_decay': 0}\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "config = {\n",
    "    'learning_rate': 0.003,\n",
    "    'dropout': 0.05,\n",
    "    'batch_size': 32,\n",
    "    'max_epochs': 20,\n",
    "    'num_workers': 4,\n",
    "    'data_dir': '../data',\n",
    "    'weight_decay': 0,\n",
    "}\n",
    "\n",
    "print(f\"Config: {config}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 19306\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "model = AdvancedMNISTCNN(\n",
    "    learning_rate=config['learning_rate'], \n",
    "    dropout=config['dropout'],\n",
    "    weight_decay=config['weight_decay']\n",
    ")\n",
    "\n",
    "data_module = MNISTDataModule(\n",
    "    batch_size=config['batch_size'],\n",
    "    data_dir=config['data_dir'],\n",
    "    num_workers=config['num_workers']\n",
    ")\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricsLogger(L.Callback):\n",
    "    def __init__(self):\n",
    "        self.train_losses = []\n",
    "        self.train_accs = []\n",
    "        self.val_losses = []\n",
    "        self.val_accs = []\n",
    "        \n",
    "    def on_train_epoch_end(self, trainer, pl_module):\n",
    "        train_loss = trainer.logged_metrics.get('train_loss', 0)\n",
    "        train_acc = trainer.logged_metrics.get('train_acc', 0)\n",
    "        self.train_losses.append(float(train_loss))\n",
    "        self.train_accs.append(float(train_acc))\n",
    "        \n",
    "    def on_validation_epoch_end(self, trainer, pl_module):\n",
    "        val_loss = trainer.logged_metrics.get('val_loss', 0)\n",
    "        val_acc = trainer.logged_metrics.get('val_acc', 0)\n",
    "        self.val_losses.append(float(val_loss))\n",
    "        self.val_accs.append(float(val_acc))\n",
    "        \n",
    "        epoch = trainer.current_epoch + 1\n",
    "        current_lr = trainer.optimizers[0].param_groups[0]['lr']\n",
    "        \n",
    "        print(\n",
    "            f\"Epoch {epoch:2d}/{config['max_epochs']} | \"\n",
    "            f\"LR: {current_lr:.6f} | \"\n",
    "            f\"Train Loss: {self.train_losses[-1]:.4f} | \"\n",
    "            f\"Train Acc: {self.train_accs[-1]:.4f} | \"\n",
    "            f\"Val Loss: {val_loss:.4f} | \"\n",
    "            f\"Val Acc: {val_acc:.4f}\"\n",
    "        )\n",
    "\n",
    "metrics_logger = MetricsLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=config['max_epochs'],\n",
    "    accelerator='auto',\n",
    "    devices=1,\n",
    "    deterministic=True,\n",
    "    callbacks=[metrics_logger],\n",
    "    enable_progress_bar=True,\n",
    "    log_every_n_steps=50\n",
    ")\n",
    "\n",
    "print(\"Starting training...\")\n",
    "trainer.fit(model, data_module)\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final validation\n",
    "val_results = trainer.validate(model, data_module)\n",
    "print(f\"\\nFinal validation results: {val_results}\")\n",
    "print(f\"Final validation accuracy: {val_results[0]['val_acc']:.4f}\")\n",
    "print(f\"Best validation accuracy: {max(metrics_logger.val_accs):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "epochs = range(1, len(metrics_logger.train_losses) + 1)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Loss curves\n",
    "ax1.plot(epochs, metrics_logger.train_losses, 'b-', label='Train Loss', linewidth=2)\n",
    "ax1.plot(epochs, metrics_logger.val_losses, 'r-', label='Validation Loss', linewidth=2)\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Training and Validation Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy curves\n",
    "ax2.plot(epochs, metrics_logger.train_accs, 'b-', label='Train Accuracy', linewidth=2)\n",
    "ax2.plot(epochs, metrics_logger.val_accs, 'r-', label='Validation Accuracy', linewidth=2)\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.set_title('Training and Validation Accuracy')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Model: AdvancedMNISTCNN\")\n",
    "print(f\"Total Parameters: {total_params:,}\")\n",
    "print(f\"Epochs: {config['max_epochs']}\")\n",
    "print(f\"Batch Size: {config['batch_size']}\")\n",
    "print(f\"Learning Rate Schedule: 0.003→0.001→0.0003→0.0001\")\n",
    "print(f\"Dropout: {config['dropout']}\")\n",
    "print(f\"Weight Decay: {config['weight_decay']}\")\n",
    "print(\"-\"*60)\n",
    "print(f\"Final Train Accuracy: {metrics_logger.train_accs[-1]:.4f}\")\n",
    "print(f\"Final Validation Accuracy: {metrics_logger.val_accs[-1]:.4f}\")\n",
    "print(f\"Best Validation Accuracy: {max(metrics_logger.val_accs):.4f}\")\n",
    "print(f\"Final Train Loss: {metrics_logger.train_losses[-1]:.6f}\")\n",
    "print(f\"Final Validation Loss: {metrics_logger.val_losses[-1]:.6f}\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
